Програма — це
опис на деякій формалізованій мові алгоритму, що вирішує поставлену задачу

Процес — це
це динамічна сутність програми, її код у процесі свого виконання

Процес адаптації алгоритмів, записаних у вигляді програм, для їх ефективного виконання на обчислювальній системі векторної архітектури називається
векторизацією

Тривіальна (проста) декомпозиція обчислювальної задачі передбачає, що
Правильна відповідь: різні копії лінійного коду можуть виконуватися незалежно один від одного і не залежать від результатів, отриманих в процесі обчислень в інших копіях коду. Проілюструвати подібний варіант можна на прикладі розв'язання задачі методом перебору або Монте-Карло. У цьому випадку одна й та ж програма, отримавши різні початкові параметри, може бути запущена на різних процесорах кластеру. Як легко помітити, програмування таких паралельних процесів нічим не відрізняється звичайного програмування на послідовному комп'ютері, за винятком маленької ділянки коду, що відповідає за запуск копій програми на процесорах кластеру та потім очікування закінчення обчислень запущених програм

Декомпозиція обчислювальної задачі по даних передбачає, що
передбачає виконання на кожному процесорі однієї і тієї ж задачі, але над різними наборами даних

Здатність мультипроцесорної системи підвищувати свою продуктивність при нарощуванні обчислювальних потужностей називається
масштабованістю

Складність алгоритму визначається
залежністю об'єму роботи, яка виконується деяким алгоритмом, від розміру вхідних даних

Часова складність алгоритму — це
час, необхідний для виконання алгоритму на даній обчислювальній машині; цей час, як правило, визначається кількістю операцій, які потрібно виконати для реалізації алгоритму

Комп'ютер може виконати алгоритм зі сталим класом складності за
мікросекунду

Комп'ютер може виконати алгоритм з лінійним класом складності за
секунду

Метод розподіленого програмування
метод, який дає змогу розподілити роботу програми між двома (або більше) процесами, причому процеси можуть існувати на тому самому комп'ютері або на різних, один з підходів до створення паралельності програмного забезпечення

Що таке степінь паралелізму
кількість операцій, які можна виконувати паралельно

Існують такі типи паралелізму
за даними , за завданнями

Паралельні обчислювальні системи за використовуваною пам’яттю поділяються на
Системи із спільною пам’яттю, Системи з розподіленою пам’яттю

За якими ресурсами вимірюється складність алгоритмів
усі відповіді правильні

Яким має бути код ОС, щоб скористатися перевагами багатопроцесорної архітектури
багатопотоковим

Архітектура з неоднорідним доступом до пам'яті називається
NUMA

NUMA система — це архітектура багатопроцесорних комп'ютерів
яка надає процесорам окремі банки пам'яті.

Яка проблема архітектури з неоднорідним доступом до пам'яті
проблема коректності та синхронізації змін в даних, які стали результатом локальних обчислень

Векторні комп'ютери є підкласом
SIMD

Система SMP відноситься до
Систем із спільною пам’яттю

Система MMP відноситься до
Систем з розподіленою пам’яттю

Система NUMA відноситься до
Систем із спільною пам’яттю

Продуктивність обчислювальних систем вимірюється в
FLOPS

Закон Амдала стверджує, що
кожному мільйону операцій в секунду процесора повинна відповідати пропускна спроможність вводу/виводу, рівна мегабіту в секунду.

Внутрішній паралелізм потоків даних із зміщенням у часі характерний для
PVP-систем

«Прискорення виконання програми за рахунок розпаралелювання її інструкцій на безлічі обчислювачів – обмежена часом, необхідним для виконання її послідовних інструкцій» – це закон
Амдала

Як оптимально використати багатоядерну платформу
Створювати один потік на одне ядро

При інкрементальному розпаралелюванні
Можна швидко отримати паралельний варіант програми, Немає необхідності розпаралелювання всієї програми

Який показник є головним для паралельних програм
Показник прискорення

Розріджена матриця - це
матриця з переважно нульовими елементами

Результатом множення матриць 15 X 70 і 65 X 17 буде матриця розміром
Множення не відбудеться

Процес адаптації алгоритмів, записаних у вигляді програм, для їх ефективного виконання на обчислювальній системі паралельної архітектури називається
розпаралелюванням

Тривіальна (проста) декомпозиція обчислювальної задачі передбачає, що
різні копії лінійного коду можуть виконуватися незалежно один від одного і не залежать від результатів, отриманих в процесі обчислень в інших копіях коду. Проілюструвати подібний варіант можна на прикладі розв'язання задачі методом перебору або Монте-Карло. У цьому випадку одна й та ж програма, отримавши різні початкові параметри, може бути запущена на різних процесорах кластеру. Як легко помітити, програмування таких паралельних процесів нічим не відрізняється звичайного програмування на послідовному комп'ютері, за винятком маленької ділянки коду, що відповідає за запуск копій програми на процесорах кластеру та потім очікування закінчення обчислень запущених програм.

Функціональна декомпозиція обчислювальної задачі передбачає, що
вихідна задача розбивається на ряд послідовних дій, які можуть бути виконані на різних вузлах кластера не залежно від проміжних результатів, але строго послідовно. За наведеним нами сценарієм дані обробляються в режимі конвеєру.

Декомпозиція обчислювальної задачі по даних передбачає, що
передбачає виконання на кожному процесорі однієї і тієї ж задачі, але над різними наборами даних.

Здатність мультипроцесорної системи підвищувати свою продуктивність при нарощуванні обчислювальних потужностей називається
масштабованістю

Розділ теоретичної інформатики, який займається дослідженням складності алгоритмів для розв'язання задач на основі формально визначених моделей обчислювальних пристроїв — це
теорія складності обчислень

Комп'ютер може виконати алгоритм з лінійним класом складності за
секунду

Один з методів розв’язку рівнянь на основі розріджених матриць
Метод спряжених градієнтів

В основу паралельної реалізації алгоритму Гауса може бути покладений принцип
розпаралелювання за даними

Найвпливовіша частина паралельного алгоритму
обмін даними

Розподілена пам’ять – накладні витрати на передачу даних
Правильно

Гіперкуб -кожен зв’язаний з двома
Неправильно

Якщо декілька змінних одночасно записують значення в спільну змінну без виконання синхронізації такий процес називається
«гонки даних»

Якщо як мінімум один потік читає значення змінної і як мінімум один потік записує значення в цю змінну без виконання синхронізації то виникають
«гонки даних»

В основу паралельної реалізації алгоритму спряжених градієнтів покладений принцип
розпаралелювання обчислень

Можливий спосіб вирішення проблеми балансування обчислень може полягати у використанні стрічкової циклічної схеми для розподілу даних між укрупненими підзадачами
Правильно

Обчислювальна складність методу сортування бульбашкою
O(n^2)

Обчислювальна складність методу сортування Шелла
O(nlog(n))

Яка операція є базовою для завдання сортування даних
"порівняти і переставити" (compare-exchange)

Що являє собою алгоритм парної-непарної перестановки
Суть полягає в тому, що в алгоритм сортування вводяться два різних правила виконання ітерацій методу: в залежності від парності або непарності номера ітерації сортування для обробки вибираються елементи з парними або непарними індексами відповідно, порівняння виділених значень завжди здійснюється з їх правими сусідніми елементами.

Які основні відмінності паралельного алгоритму сортування Шелла від методу парної-непарної перестановки
Усі відповіді вірні.

Що залежить від правильного вибору провідного елементу для паралельного алгоритму швидкого сортування
Ефективність швидкого сортуванн

Для яких топологій можуть застосовуватися розглянуті алгоритми сортування
топології мережі передачі даних у вигляді гіперкуба

Складність правильності вибору значень провідних елементів у методі швидкого сортування  може бути знижена, якщо виконати впорядкування локальних блоків процесорів перед початком сортування і забезпечити однорідний розподіл сортуючих даних між процесорами обчислювальної системи
Правильно

Організація паралельних обчислень при  сортуванні з використанням регулярного набору зразків не дозволяє отримувати прискорення обчислювального процесу
Неправильно

Для методів сортування в якості базової підзадачі для організації паралельних обчислень може бути обрана операція "порівняти і розділити"
Правильно

Що виконує функція (int/logical) omp_in_parallel()
Дозволяє ідентифікувати в якій ділянці програми (паралельній/послідовній) в даний момент проводяться обчислення

В динамічному режимі роботи
Передача значення змінної з одного паралельного структурного блока в інший не допускається

Коли ініціалізуються змінні, що включені в список директив threadprivate
До початку першого паралельного блоку

Директива OpenMP for використовується для
організації паралельного виконання петель циклів в програмах написаних на мові С/С++

Вкажіть директиви, з якими оператори паралельної ділянки не будуть виконуватися одночасно двома або більше потоками
Critical

Який номер має головний потік(OpenMP)
0

Скільки разів може відбуватися ініціалізація змінних, що включені в список директив threadprivate
Ініціалізація можлива тільки один раз

З якого значення починається відлік звичайних (не головних) потоків
1

Що виконує функція (int/logical) omp_get_nested()
Дозволяє ідентифікувати встановлений або не вкладений режим паралельної ділянки програми

З того значення яке задасть користувач
значенням OMP_NUM_THREADS, спеціальними функціями викликаними всередині програми

Що виконує функція (void) omp_set_dynamic( TRUE | FALSE )
Задає або відміняє динамічний режим роботи

Директиви компілятора (OpenMP) використовуються для
Створення потоків, розподілу роботи між потоками і їх синхронізації

Для чого використовується директива OpenMP copyin
Для передачі даних із головного потоку в паралельні

Процедура OMP_TEST_LOCK
Здійснює спробу захвату вказаного замка якщо це в неї не виходить то повертає значення False.

Передача значення змінної з одного паралельного структурного блока в інший буде не коректною
Ініціалізація можлива тільки один раз

Даний фрагмент OpenMP-програми: #pragma omp директива { оператори } Вкажіть директиви, з якими оператори паралельної ділянки  будуть виконуватися тільки одним потоком
Master, Single

Які моделі паралельного програмування реалізовані в стандарті OpenMP
Спільна пам’ять, Паралелізм "fork-join"

MPI - це
стандарт, який базується на моделі передачі повідомлень.

Вкажіть правильне твердження
MPI це програмний інтерфейс для передачі інформації, який дозволяє обмінюватися повідомленнями між процесами, що виконують одну задачу

Номер процесу в MPI програмі це
ціле невід'ємне число, що є унікальним атрибутом кожного процесу

Для ініціалізації паралельної частини MPI програми використовується
MPI_Init

Процедура MPI_Comm_size використовується для
Визначення загального числа паралельних процесів в груп

Комунікатор MPI_COMM_SELF містить
Поточний процес

Функція MPI_WTIME повертає
астрономічний час в секундах що пройшов з деякого моменту в минулому

Для чого призначена наступна процедура : MPI_SEND(BUF, COUNT, DATATYPE, DEST, MSGTAG, COMM, IERR)
Блокуюча посилка масиву BUF з ідентифікатором MSGTAG, що складається з COUNT елементів типу DATATYPE, процесу з номером DEST в комунікаторі COMM

Якщо один процес послідовно посилає два повідомлення, відповідні одному і тому ж виклику MPI_RECV, іншому процесу, то першим буде прийнято повідомлення, яке
Було відправлено раніше

Процедура MPI_START призначена для
Ініціалізації відкладеного запиту на виконання операції обміну

Функція MPI_TYPE_CONTIGUOUS використовується для
Створення нового типу даних

Для створення нової групи з об’єднання двох груп використовується функція
MPI_GROUP_UNION

Для створення нової групи з перетину двох груп використовується функція
MPI_GROUP_INTERSECTION

Група в MPI-програмі це
Упорядкована множина процесів

Значення MPI_GROUP_EMPTY використовується для
Пустої групи

Функція MPI_COMM_GROUP(COMM, GROUP, IERR) використовується для
Отримання групи GROUP, відповідної комунікатору COMM

Функція MPI_INITIALIZED(FLAG, IERR) в аргументі FLAG повертає TRUE, якщо
викликана з паралельної частини програми

В стандарті MPI передбачається наявність
Більше 125 функцій

Для передачі даних між процесами з різних груп необхідно створити
Глобальний комунікатор

Номер процесу називається
Рангом процесу

Кількість процесів і число використовуваних процесорів для MPI-програм визначається
в момент запуску паралельної програми засобами середовища виконання MPI-програм

Кожен процес паралельної MPI-програми породжується на основі
копії одного і того ж програмного коду

Процеси MPI-програми можуть виконуватися
На одному або на різних процесорах

Під паралельною програмою в рамках MPI розуміється
безліч одночасно виконуваних процесів

Операції обміну в MPI-програмі можливі між
Процесами, що належать до одного комунікатора

Абревіатура OpenCL розшифровується як
Open Computing Language

Для компіляції програм на мові С з засобами nVidia CUDA у середовищі Linux використовується команда
nvcc src_file.c -o run_file

Головною перевагою методу Кеннона є те, що
вимоги до пам’яті залишаються постійними і не залежать від кількості процесорів

OpenCL – це
фреймворк призначений для паралельного програмування на гетерогенних системах

До апаратно-залежних платформ належить
CUDA, FireStream

У кластерних системах
процесорними елементами виступають однопроцесорні або SMP-комп'ютери, міжвузлові комунікації — стандартні мережеві інтерфейси

Уніфікованою технологією програмування обчислювальних пристроїв, зокрема графічних плат для обчислювальних задач загального призначення є бібліотека
OpenGL

GPGPU передбачає
використання графічного процесору для виконання обчислень

Центр сертифікації (Certificate Authority – CA) – це
спеціальна організація, що володіє повноваженнями видавати (підписувати) цифрові сертифікати.

В технології CUDA частина програми, яка буде виконуватися на GPU, називається
kernel

Чи вірне твердження, що OpenCL надає можливість програмувати тільки на GPU
Неправильно

В технології CUDA частина програми, яка буде виконуватися на CPU, називається
host

До апаратно-незалежних платформ належить
OpenCL

Програму на CUDA можна логічно розділити на дві частини, перша частина (керуюча) виконується на CPU, друга частина (обчислювальна) виконується на GPU
Правильно

Чи вірне твердження, що в технології CUDA частина програми, яка буде виконуватися на GPU, має бути написана на мові CUDA
так

OpenCL є розширенням мови
C

Бібліотека CUBLAS розроблена компанією
Nvidia

CUDA - це
Compute Unified Device Architecture

Чи вірне твердження, що в технології CUDA частина програми, яка буде виконуватися на CPU, має бути написана на мові CUDA
ні

Які протоколи та стандарти мережевих з'єднань використовуються в GRID-системах
web-орієнтовані, XML-орієнтовані, такі, що базуються на web-сервісах

Адміністратор з безпеки грід-сайту, або представник з безпеки грід-сайту (Site Security Contact) – це
особа, яка відповідає за безпеку роботи сервісів грід-сайту, аналізує загрози безпеці грід-мережі і встановлених сервісів, проводить дослідження інцидентів безпеки та діє як контактна особа у випадках інцидентів, що стосуються питань комп'ютерної або мережевої безпеки грід-сайту.

Що таке грід
це розподілене програмно-апаратне комп’ютерне середовище із розподіленою організацією високопродуктивних обчислень та керування робочим навантаженням і потоками даних.

Є два основні критерії, що виділяють Grid-системи (або інфраструктури) серед інших систем, що забезпечують доступ, до ресурсів
Grid-система координує розрізнені ресурси., Grid-система будується на базі стандартних і відкритих протоколів, сервісів і інтерфейсів.

Найчастіше реалізації Grid-систем забезпечують роботу з наступними типами ресурсів
обчислювальні ресурси – окремі комп’ютери, кластери;, ресурси зберігання даних – диски і дискові масиви, стрічки, системи масового зберігання даних;, мережеві ресурси;, програмне забезпечення – яке-небудь спеціалізоване ПЗ

Найбільш важливим стандартом, покликаним визначити загальну, стандартну і відкриту архітектуру грід, є стандарт
Open Grid Services Architecture (OGSA).

Перша конкретизація OGSA була здійснена в документі
Open Grid Services Infrastructure (OGSI).

Фактичним стандартом безпеки в грід є
Grid Security Infrastructure (GSI).

ARC забезпечує такі функції
інформаційні (збір і надання інформації про ресурси Грід-системи);, динамічне включення ресурсів до Грід-системи і їхній моніторинг;, відправлення завдань на виконання в Грід-систему і керування завданнями;, розподіл завдань по ресурсах;, керування даними й ресурсами;

Грід-менеджер (Grid Manager, GM) – це
сервіс керування завданнями користувачів.

Grid FTPServer – це
сервіс, що забезпечує доступ до файлової системи.

Грід-сервіс (Grid Service) – це
це програмна, чи програмно-апаратна одиниця в складі національної грід-інфраструктури, що реалізує послуги, необхідні для повноцінного функціонування чи використання гріду.
